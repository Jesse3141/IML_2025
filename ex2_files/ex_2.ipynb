{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2232d0a0-c06e-430a-9eca-928881efed74",
   "metadata": {},
   "source": [
    "in this note book we implement excercise 2.\n",
    "\n",
    "\n",
    "we will be working interactivley:\n",
    "\n",
    "load variables into global and interact in jupyter. only things work and are understood, do we move to classes and fucntions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49fe2b-40f0-44f2-9230-4bae4a464030",
   "metadata": {},
   "source": [
    "# imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a1b46",
   "metadata": {
    "time_run": "6:42:23a"
   },
   "outputs": [],
   "source": [
    "import sys, os\r\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4597f9-6a8e-40ba-b0c8-e223cb5733f1",
   "metadata": {
    "time_run": "6:42:30a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from helpers import *\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ba8f2-ed8a-4417-8bee-7b25eb67a96f",
   "metadata": {},
   "source": [
    "## brief summary of methods in helpers\n",
    "\n",
    "**Helper functions:**\n",
    "- `decision_tree_demo()`: Demo of training/predicting with DecisionTreeClassifier\n",
    "- `loading_random_forest()`: Shows how to initialize RandomForestClassifier with 300 trees, max_depth=6\n",
    "- `loading_xgboost()`: Shows how to initialize XGBClassifier with 300 trees, max_depth=6, lr=0.1\n",
    "- `plot_decision_boundaries(model, X, y, title)`: Visualizes classifier decision boundaries on 2D space\n",
    "- `knn_examples(X_train, Y_train, X_test, Y_test)`: Demo of training/predicting with KNNClassifier\n",
    "- `read_data_demo(filename)`: Reads CSV and returns numpy array + column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c60ff4-ed3c-4afc-9ce3-f0a32e40788b",
   "metadata": {},
   "source": [
    "## data overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab3567-dadd-4ef5-8520-2d74b7aa42a0",
   "metadata": {},
   "source": [
    "**Task:** Create paths to all CSV files (train.csv, validation.csv, test.csv, AD_test.csv). Print first few rows of train and AD_test. Print shapes of all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e00baf",
   "metadata": {
    "time_run": "6:42:30a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/app/data/IML_2025/ex2_files')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad0388",
   "metadata": {
    "time_run": "6:42:30a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('/app/data/IML_2025/ex2_files/AD_test.csv'),\n",
       " Path('/app/data/IML_2025/ex2_files/ex_2.py'),\n",
       " Path('/app/data/IML_2025/ex2_files/ex2.pdf'),\n",
       " Path('/app/data/IML_2025/ex2_files/knn.py'),\n",
       " Path('/app/data/IML_2025/ex2_files/validation.csv'),\n",
       " Path('/app/data/IML_2025/ex2_files/__MACOSX'),\n",
       " Path('/app/data/IML_2025/ex2_files/test.csv'),\n",
       " Path('/app/data/IML_2025/ex2_files/ex2_instructions.md'),\n",
       " Path('/app/data/IML_2025/ex2_files/helpers.py'),\n",
       " Path('/app/data/IML_2025/ex2_files/train.csv'),\n",
       " Path('/app/data/IML_2025/ex2_files/ex_2.ipynb'),\n",
       " Path('/app/data/IML_2025/ex2_files/__pycache__')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(Path.cwd().iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fa93a3",
   "metadata": {
    "time_run": "6:42:30a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('train.csv'),\n",
       " Path('validation.csv'),\n",
       " Path('test.csv'),\n",
       " Path('AD_test.csv'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = Path('train.csv')\n",
    "val_path = Path('validation.csv')\n",
    "test_path = Path('test.csv')\n",
    "ad_test_path = Path('AD_test.csv')\n",
    "\n",
    "train_path, val_path, test_path, ad_test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146dc383",
   "metadata": {
    "time_run": "6:42:30a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data first 5 rows:\n",
      "[[-90.2232  33.1831  22.    ]\n",
      " [-91.3027  36.0799   1.    ]\n",
      " [-95.7114  32.6776  40.    ]\n",
      " [-93.5819  42.3102   9.    ]\n",
      " [-81.23    40.8873  32.    ]]\n",
      "\n",
      "Train columns: ['long', 'lat', 'state']\n",
      "\n",
      "AD_test data first 5 rows:\n",
      "[[34.78   32.08  ]\n",
      " [35.2066 31.7784]\n",
      " [34.9992 32.8192]\n",
      " [34.8    31.95  ]\n",
      " [34.8864 32.0889]]\n",
      "\n",
      "AD_test columns: ['long', 'lat']\n"
     ]
    }
   ],
   "source": [
    "train_data, train_cols = read_data_demo(train_path)\n",
    "ad_test_data, ad_test_cols = read_data_demo(ad_test_path)\n",
    "\n",
    "print(f\"Train data first 5 rows:\\n{train_data[:5]}\\n\")\n",
    "print(f\"Train columns: {train_cols}\\n\")\n",
    "print(f\"AD_test data first 5 rows:\\n{ad_test_data[:5]}\\n\")\n",
    "print(f\"AD_test columns: {ad_test_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4345fbe5-18ae-4bb9-8351-34655e265789",
   "metadata": {},
   "source": [
    "# part 1: KNN iplementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a28e4a-246a-49f5-b1cf-2f011b5e20f3",
   "metadata": {},
   "source": [
    "specification notes\n",
    "\n",
    "Algorithm 1: kNN Classification\n",
    "\n",
    "Data: Training dataset Xtrain = {(xi, yi)}N\n",
    "\n",
    "i=1, where xi âˆˆ R2 is the\n",
    "\n",
    "feature vector and yi corresponds to its class label; Test instance\n",
    "Ë†xtest; Number of neighbors k.\n",
    "\n",
    "Result: Predicted class label Ë†ytest for the test instance.\n",
    "for each training instance (xi, yi) do\n",
    "\n",
    "Calculate the distance di between xi and xtest.\n",
    "\n",
    "Sort the distances di in ascending order and select the first k instances.\n",
    "for each class c do\n",
    "\n",
    "Count the occurrences of c in the selected k instances.\n",
    "Assign the class label Ë†ytest to the one with the highest count.\n",
    "return Ë†ytest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e10a6-afde-4f8a-a3cb-69e1b183cb46",
   "metadata": {
    "time_run": "7:16:29a"
   },
   "outputs": [],
   "source": [
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k, distance_metric='l2'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train = None\n",
    "        self.Y_train = None\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        Update the kNN classifier with the provided training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train (numpy array) of size (N, d): Training feature vectors.\n",
    "        - Y_train (numpy array) of size (N,): Corresponding class labels.\n",
    "        \"\"\"\n",
    "        self.X_train = X_train.astype(np.float32)\n",
    "        self.Y_train = Y_train\n",
    "        d = self.X_train.shape[1]\n",
    "        if self.distance_metric == 'l2':\n",
    "            self.index = faiss.index_factory(d, \"Flat\", faiss.METRIC_L2)\n",
    "        elif self.distance_metric == 'l1':\n",
    "            self.index = faiss.index_factory(d, \"Flat\", faiss.METRIC_L1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        pass\n",
    "        self.index.add(self.X_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels for the given data.\n",
    "\n",
    "        Parameters:\n",
    "        - X (numpy array) of size (M, d): Feature vectors.\n",
    "\n",
    "        Returns:\n",
    "        - (numpy array) of size (M,): Predicted class labels.\n",
    "        \"\"\"\n",
    "        X = X.astype(np.float32)\n",
    "        distances, indices = self.index.search(X, self.k)\n",
    "        neighbor_labels = self.Y_train[indices]\n",
    "        return np.array([np.bincount(row.astype(int)).argmax() for row in neighbor_labels])\n",
    "\n",
    "    def knn_distance(self, X):\n",
    "        \"\"\"\n",
    "        Calculate kNN distances for the given data. You must use the faiss library to compute the distances.\n",
    "        See lecture slides and https://github.com/facebookresearch/faiss/wiki/Getting-started#in-python-2 for more information.\n",
    "\n",
    "        Parameters:\n",
    "        - X (numpy array) of size (M, d): Feature vectors.\n",
    "\n",
    "        Returns:\n",
    "        - (numpy array) of size (M, k): kNN distances.\n",
    "        - (numpy array) of size (M, k): Indices of kNNs.\n",
    "        \"\"\"\n",
    "        X = X.astype(np.float32)\n",
    "        return self.index.search(X, self.k)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640363c4-673a-4d8c-880a-cd6091555360",
   "metadata": {},
   "source": [
    "things i need to understand:\n",
    "\n",
    "how does faiss knn work? what happens in fit?\n",
    "we need to be able to play with the internals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10beae14",
   "metadata": {
    "time_run": "7:00:17a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24031, 2), (24031,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNNClassifier(k=5, distance_metric='l2')\n",
    "knn.fit(train_data[:, :2], train_data[:, 2])\n",
    "knn.X_train.shape, knn.Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4701d0c",
   "metadata": {},
   "source": [
    "so the function we cate baout is faiss.index.search.\r\n",
    "\r\n",
    "I assume that index.add(ndarrary) creates some kind of idexible rid over all samples to allow efficient finding of neighbours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9048f20",
   "metadata": {
    "collapsed": true,
    "skipped": true,
    "time_run": "6:42:30a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m knn.index.search(x, k, *, params=\u001b[38;5;28;01mNone\u001b[39;00m, D=\u001b[38;5;28;01mNone\u001b[39;00m, I=\u001b[38;5;28;01mNone\u001b[39;00m, numeric_type=\u001b[32m0\u001b[39m)\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Find the k nearest neighbors of the set of vectors x in the index.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "x : array_like\n",
       "    Query vectors, shape (n, d) where d is appropriate for the index.\n",
       "    `dtype` must be float32.\n",
       "k : int\n",
       "    Number of nearest neighbors.\n",
       "params : SearchParameters\n",
       "    Search parameters of the current search (overrides the class-level params)\n",
       "D : array_like, optional\n",
       "    Distance array to store the result.\n",
       "I : array_like, optional\n",
       "    Labels array to store the results.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "D : array_like\n",
       "    Distances of the nearest neighbors, shape (n, k). When not enough results are found\n",
       "    the label is set to +Inf or -Inf.\n",
       "I : array_like\n",
       "    Labels of the nearest neighbors, shape (n, k).\n",
       "    When not enough results are found, the label is set to -1\n",
       "\u001b[31mFile:\u001b[39m      ~/.local/lib/python3.12/site-packages/faiss/class_wrappers.py\n",
       "\u001b[31mType:\u001b[39m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?knn.index.search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80959b1e",
   "metadata": {
    "time_run": "6:45:22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query point: [[35. 32.]]\n",
      "\n",
      "Distances shape: (1, 5)\n",
      "Indices shape: (1, 5)\n",
      "\n",
      "Distances: [[10574.498 10622.248 10675.835 10743.521 10768.449]]\n",
      "Indices: [[ 2682  6092 23297  9682 21731]]\n"
     ]
    }
   ],
   "source": [
    "test_point = np.array([[35.0, 32.0]], dtype=np.float32)\n",
    "distances, indices = knn.index.search(test_point, k=5)\n",
    "print(f\"Query point: {test_point}\")\n",
    "print(f\"\\nDistances shape: {distances.shape}\")\n",
    "print(f\"Indices shape: {indices.shape}\")\n",
    "print(f\"\\nDistances: {distances}\")\n",
    "print(f\"Indices: {indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadf5b9e",
   "metadata": {
    "time_run": "6:45:39a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbor coordinates:\n",
      "[[-67.0183  44.9137]\n",
      " [-67.224   45.134 ]\n",
      " [-67.4293  45.5674]\n",
      " [-67.8903  44.5343]\n",
      " [-67.8682  45.6595]]\n",
      "\n",
      "Neighbor labels: [18. 18. 18. 18. 18.]\n"
     ]
    }
   ],
   "source": [
    "neighbor_points = knn.X_train[indices[0]]\n",
    "neighbor_labels = knn.Y_train[indices[0]]\n",
    "print(f\"Neighbor coordinates:\\n{neighbor_points}\")\n",
    "print(f\"\\nNeighbor labels: {neighbor_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae032fe",
   "metadata": {},
   "source": [
    "and use `np.bincount` to get the counts of all labels. creates a bin up to max of largest in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6c53d2",
   "metadata": {
    "time_run": "6:46:27a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(18)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(neighbor_labels.astype(int)).argmax()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4aa587",
   "metadata": {},
   "source": [
    "and for an array input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3abd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_points = np.array([[35.0, 32.0], [34.5, 31.5], [36.0, 33.0], [35.5, 32.5], [34.0, 31.0]], dtype=np.float32)\n",
    "distances, indices = knn.index.search(test_points, k=5)\n",
    "neighbor_labels = knn.Y_train[indices]\n",
    "predicted_labels = np.array([np.bincount(row.astype(int)).argmax() for row in neighbor_labels])\n",
    "print(f\"Test points shape: {test_points.shape}\")\n",
    "print(f\"Distances shape: {distances.shape}\")\n",
    "print(f\"Indices shape: {indices.shape}\")\n",
    "print(f\"Neighbor labels shape: {neighbor_labels.shape}\")\n",
    "print(f\"Predicted labels: {predicted_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93139565",
   "metadata": {
    "time_run": "7:00:22a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 18, 18, 18, 18])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(test_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe1d0fc",
   "metadata": {
    "skipped": true,
    "solveit_ai": true,
    "use_thinking": true
   },
   "source": [
    "nwo help me impelement the knn class knn_distances:\r\n",
    "\r\n",
    "        Parameters:\r\n",
    "        - X (numpy array) of size (M, d): Feature vectors.\r\n",
    "\r\n",
    "        Returns:\r\n",
    "        - (numpy array) of size (M, k): kNN distances.\r\n",
    "        - (numpy array) of size (M, k): Indices of kNNs.\r\n",
    "\r\n",
    "\r\n",
    "    simply use fias on new data to get all the disatnces. \r\n",
    "    what might b more efficient\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ ðŸ§ \n",
    "\n",
    "Looking at your exploration above, you've already figured out the key part! Here's the implementation:\n",
    "\n",
    "```python\n",
    "def knn_distance(self, X):\n",
    "    \"Calculate kNN distances for the given data\"\n",
    "    X = X.astype(np.float32)\n",
    "    return self.index.search(X, self.k)\n",
    "```\n",
    "\n",
    "This returns a tuple of (distances, indices) which matches your required output. The faiss index already has the efficient search structure built from `.fit()`, so it's just a direct search call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8715e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_distance(self, X):\n",
    "    \"Calculate kNN distances for the given data\"\n",
    "    X = X.astype(np.float32)\n",
    "    return self.index.search(X, self.k)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a51408e",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "now lets run  a train test run. trian the knn on train data, then predict on test and get test accuarcy\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "val_data, val_cols = read_data_demo(val_path)\n",
    "X_val, Y_val = val_data[:, :2], val_data[:, 2]\n",
    "knn = KNNClassifier(k=5, distance_metric='l2')\n",
    "knn.fit(train_data[:, :2], train_data[:, 2])\n",
    "preds = knn.predict(X_val.astype(np.float32))\n",
    "(preds == Y_val).mean()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afce37f",
   "metadata": {
    "time_run": "7:18:41a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9717043941411452)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data, val_cols = read_data_demo(val_path)\n",
    "X_val, Y_val = val_data[:, :2], val_data[:, 2]\n",
    "knn = KNNClassifier(k=5, distance_metric='l2')\n",
    "knn.fit(train_data[:, :2], train_data[:, 2])\n",
    "preds = knn.predict(X_val.astype(np.float32))\n",
    "(preds == Y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d6480",
   "metadata": {
    "time_run": "7:26:08a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Class in Train: 40\n",
      "Frequency in Train: 6.11%\n",
      "Baseline (Majority Vote) Accuracy: 0.0613\n",
      "\n",
      "Your KNN Results for large k:\n",
      "      k metric  accuracy\n",
      "8  3000     l1  0.401798\n",
      "9  3000     l2  0.398136\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "# 1. Identify the majority class in the training set\r\n",
    "y_train_labels = train_data[:, 2].astype(int)\r\n",
    "counts = np.bincount(y_train_labels)\r\n",
    "majority_class = counts.argmax()\r\n",
    "majority_frequency = counts.max() / len(y_train_labels)\r\n",
    "\r\n",
    "print(f\"Majority Class in Train: {majority_class}\")\r\n",
    "print(f\"Frequency in Train: {majority_frequency:.2%}\")\r\n",
    "\r\n",
    "# 2. Calculate the accuracy on Test set if we ONLY predicted that class\r\n",
    "# (This is the theoretical limit as k -> N)\r\n",
    "baseline_accuracy = (Y_test == majority_class).mean()\r\n",
    "\r\n",
    "print(f\"Baseline (Majority Vote) Accuracy: {baseline_accuracy:.4f}\")\r\n",
    "\r\n",
    "# 3. Compare with your specific result for k=3000\r\n",
    "print(\"\\nYour KNN Results for large k:\")\r\n",
    "print(df[df['k'] == 3000][['k', 'metric', 'accuracy']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9865b59-ce50-4d69-b9e1-8809f42600dc",
   "metadata": {},
   "source": [
    "**Grid search:** Train kNN for all combinations of k âˆˆ {1, 10, 100, 1000, 3000} Ã— distance âˆˆ {L1, L2}. Create 5Ã—2 table of test accuracies. Save all 10 models with their hyperparameters and test accuracies.\n",
    "\n",
    "**Questions:**\n",
    "1. What's the trend as k increases? Does it differ by distance metric?\n",
    "2. Visualize decision boundaries for: (i) L2 with k_max (best accuracy), (ii) L2 with k_min (worst accuracy), (iii) L1 with k_max\n",
    "   - (a) Compare k_max vs k_min with L2: why does k_max perform better?\n",
    "   - (b) Compare L2 vs L1 with k_max: how does distance metric affect the space?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37798c3-0eb1-47ae-ab2a-e313b5d841ae",
   "metadata": {},
   "source": [
    "think about the problem - what would you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7ed1b-53ae-4a0c-9659-b388a32f4bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dcd741",
   "metadata": {
    "time_run": "7:24:25a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.967044</td>\n",
       "      <td>0.968375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.961718</td>\n",
       "      <td>0.957723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.923103</td>\n",
       "      <td>0.920107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.745007</td>\n",
       "      <td>0.741678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0.401798</td>\n",
       "      <td>0.398136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric        l1        l2\n",
       "k                         \n",
       "1       0.967044  0.968375\n",
       "10      0.961718  0.957723\n",
       "100     0.923103  0.920107\n",
       "1000    0.745007  0.741678\n",
       "3000    0.401798  0.398136"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#params\r\n",
    "knn_size = [1,10,100,1000,3000]\r\n",
    "metric = ['l1','l2']\r\n",
    "\r\n",
    "train_data, train_cols = read_data_demo(train_path)\r\n",
    "import pandas as pd\r\n",
    "results = []\r\n",
    "for k in knn_size:\r\n",
    "    for m in metric:\r\n",
    "        knn = KNNClassifier(k=k, distance_metric=m)\r\n",
    "        knn.fit(train_data[:, :2], train_data[:, 2])\r\n",
    "        preds = knn.predict(X_test)\r\n",
    "        acc = (preds == Y_test).mean()\r\n",
    "        results.append(dict(k=k, metric=m, accuracy=acc))\r\n",
    "df = pd.DataFrame(results)\r\n",
    "df.pivot(index='k', columns='metric', values='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0e56e",
   "metadata": {},
   "source": [
    "as excpected, beyond some point, as K grows, the classifier just predicts the most common labels overall (if there is an over-represented state, then with very large k that tends to be the reuslt). hence beyond 10, the model detriorates. furthermore, since this model will only struggle with cities near borders, it is unsurprising that k=1 performed best.\r\n",
    "\r\n",
    "furthermore, l1 perforemed slightly better than l2. since each computes distance slightly differnetly, this is an artifact of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d311c95-3f85-4863-9ffe-2e25696a7e65",
   "metadata": {},
   "source": [
    "### KNN decision boundaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a3645b-59fd-4e09-aa12-9c3fc5b9f998",
   "metadata": {},
   "source": [
    "**Task:** Use `plot_decision_boundaries()` helper to visualize 3 models on test data:\n",
    "1. L2 distance, k = k_max (highest test accuracy)\n",
    "2. L2 distance, k = k_min (lowest test accuracy)  \n",
    "3. L1 distance, k = k_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe852eb2-7baa-4860-a888-b80c8a7a0d8a",
   "metadata": {},
   "source": [
    "## Anomaly detection\n",
    "\n",
    "**Task:** Use AD_test.csv as test set, train.csv as single class (ignore labels).\n",
    "1. Find 5 nearest neighbors (L2 distance) for each AD_test sample\n",
    "2. Sum the 5 distances = anomaly score per sample\n",
    "3. Select top 50 samples with highest scores = anomalies, rest = normal\n",
    "4. Plot: AD_test colored by prediction (blue=normal, red=anomaly) + train.csv in black with alpha=0.01\n",
    "\n",
    "**Question:** What characterizes the anomalies? How do they differ from normal data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff9845-2dee-4fea-b3f2-68cc354c2155",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "934e3feb-fe02-4377-bffc-07f595685cf0",
   "metadata": {},
   "source": [
    "# trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d86026c-ae06-4ef7-88f8-b9d48513b271",
   "metadata": {},
   "source": [
    "## Understanding trees - interactive exploration\n",
    "\n",
    "**Goal:** Interact with tree components to understand how predictions work.\n",
    "- Create a simple tree, examine its structure (tree_.feature, tree_.threshold, tree_.children_left/right, tree_.value)\n",
    "- Manually trace a prediction path for a sample point\n",
    "- Understand how tree.predict() navigates the tree structure\n",
    "\n",
    "**Visualization library:** `sklearn.tree.plot_tree()` or `graphviz` for tree visualization. For more advanced viz, use `dtreeviz` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aijcnadqci",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree visualization series placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4yzzs4x68vr",
   "metadata": {},
   "source": [
    "## Visualizing tree complexity\n",
    "\n",
    "**Series 1 - Fixed depth=1, varying leaves:**\n",
    "Train and visualize trees with max_depth=1 and max_leaf_nodes âˆˆ {2, 4, 8, 24, 50, 100}\n",
    "\n",
    "**Series 2 - Varying depth, controlled leaves:**\n",
    "Train and visualize trees with max_depth âˆˆ {2, 4, 8, 16, 32, 50} and appropriate max_leaf_nodes to observe depth effects\n",
    "\n",
    "**Goal:** Understand how depth vs leaf constraints affect tree structure and decision boundaries.\n",
    "\n",
    "**Visualization:** Use `sklearn.tree.plot_tree()` for tree structure or `plot_decision_boundaries()` for geographic space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85450dee-9e03-42b9-a915-aca5a5f1e154",
   "metadata": {},
   "source": [
    "## train 24 trees\n",
    "\n",
    "**Task:** Train DecisionTreeClassifier for all combinations of max_depth âˆˆ {1, 2, 4, 6, 10, 20, 50, 100} Ã— max_leaf_nodes âˆˆ {50, 100, 1000}. Save all 24 models with their hyperparameters (max_depth, max_leaf_nodes) and accuracies (train, validation, test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae74f7-7122-4530-9c2a-8f4eb94fc738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc7b504-2620-49f3-9c4c-6ba111c8e029",
   "metadata": {},
   "source": [
    "## tree analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100e318-b5dd-408d-bfb2-98674fdae772",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "1. Report test accuracy of tree with best validation accuracy\n",
    "2. Does this tree generalize well? Is validation set sufficient for selection?\n",
    "3. Are 50 leaf nodes enough for perfect accuracy with 50 states? Why/why not?\n",
    "4. Visualize decision boundaries for best tree from Q1. What shapes do classes form?\n",
    "5. Find best tree with exactly 50 leaf nodes. Visualize and compare to Q1 best tree.\n",
    "6. Find best tree with max_depth â‰¤ 6. Visualize and compare space division to Q4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6604b-51a4-4073-98fe-a7fb917c55f2",
   "metadata": {},
   "source": [
    "think and research - how many leaves do trees? how many boundaries can a tree make? how many hyper planes?\n",
    "\n",
    "ask chat gpt for deep think"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9746815-6cf6-4507-adc6-c9a7509780d7",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f03b78f-6f2c-43b2-afac-29a153b44088",
   "metadata": {},
   "source": [
    "**Task:** Train RandomForestClassifier with n_estimators=300, max_depth=6. Visualize decision boundaries. \n",
    "\n",
    "**Question:** Is this model more expressive than single tree from Q1? How does visualization show this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea7c1f-4639-4ffe-873b-87842cc4e0cd",
   "metadata": {},
   "source": [
    "# bonus: boosted trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecaa860-800d-4189-8b59-b68a43f0dab9",
   "metadata": {},
   "source": [
    "**Bonus (5 pts):** Train XGBClassifier with n_estimators=300, max_depth=6, learning_rate=0.1. Report test accuracy and visualize predictions. Compare to random forest: how do predictions differ? Which performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da80513-2a81-462f-afab-e47b305be6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff5c4634-9135-4d25-ac39-28c81d23eac3",
   "metadata": {},
   "source": [
    "## interpret Ml explainable boosting classifier\n",
    "\n",
    "instead of xgb trees, use the glassbox EBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a988d2-cc9f-4ad3-931e-932d53df3b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069337c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "concise",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
