{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2232d0a0-c06e-430a-9eca-928881efed74",
   "metadata": {},
   "source": [
    "in this note book we implement excercise 2.\n",
    "\n",
    "\n",
    "we will be working interactivley:\n",
    "\n",
    "load variables into global and interact in jupyter. only things work and are understood, do we move to classes and fucntions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc49fe2b-40f0-44f2-9230-4bae4a464030",
   "metadata": {},
   "source": [
    "# imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a1b46",
   "metadata": {
    "time_run": "2:46:44p"
   },
   "outputs": [],
   "source": [
    "import sys, os\r\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4597f9-6a8e-40ba-b0c8-e223cb5733f1",
   "metadata": {
    "time_run": "2:47:49p"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ba8f2-ed8a-4417-8bee-7b25eb67a96f",
   "metadata": {},
   "source": [
    "## brief summary of methods in helpers\n",
    "\n",
    "**Helper functions:**\n",
    "- `decision_tree_demo()`: Demo of training/predicting with DecisionTreeClassifier\n",
    "- `loading_random_forest()`: Shows how to initialize RandomForestClassifier with 300 trees, max_depth=6\n",
    "- `loading_xgboost()`: Shows how to initialize XGBClassifier with 300 trees, max_depth=6, lr=0.1\n",
    "- `plot_decision_boundaries(model, X, y, title)`: Visualizes classifier decision boundaries on 2D space\n",
    "- `knn_examples(X_train, Y_train, X_test, Y_test)`: Demo of training/predicting with KNNClassifier\n",
    "- `read_data_demo(filename)`: Reads CSV and returns numpy array + column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c60ff4-ed3c-4afc-9ce3-f0a32e40788b",
   "metadata": {},
   "source": [
    "## data overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab3567-dadd-4ef5-8520-2d74b7aa42a0",
   "metadata": {},
   "source": [
    "**Task:** Create paths to all CSV files (train.csv, validation.csv, test.csv, AD_test.csv). Print first few rows of train and AD_test. Print shapes of all datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7218e3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "help me create heper vars holding paths to data files and to visualise fist few enteries of data and their shape\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path('data')\n",
    "train_path = data_dir/'train.csv'\n",
    "val_path = data_dir/'validation.csv'\n",
    "test_path = data_dir/'test.csv'\n",
    "ad_test_path = data_dir/'AD_test.csv'\n",
    "\n",
    "train_path, val_path, test_path, ad_test_path\n",
    "```\n",
    "\n",
    "Once you run that, we can load and visualize the data:\n",
    "\n",
    "```python\n",
    "train_data, train_cols = read_data_demo(train_path)\n",
    "ad_test_data, ad_test_cols = read_data_demo(ad_test_path)\n",
    "\n",
    "print(f\"Train data first 5 rows:\\n{train_data[:5]}\\n\")\n",
    "print(f\"Train columns: {train_cols}\\n\")\n",
    "print(f\"AD_test data first 5 rows:\\n{ad_test_data[:5]}\\n\")\n",
    "print(f\"AD_test columns: {ad_test_cols}\")\n",
    "```\n",
    "\n",
    "Then check all shapes:\n",
    "\n",
    "```python\n",
    "val_data, _ = read_data_demo(val_path)\n",
    "test_data, _ = read_data_demo(test_path)\n",
    "\n",
    "print(f\"Train shape: {train_data.shape}\")\n",
    "print(f\"Validation shape: {val_data.shape}\")\n",
    "print(f\"Test shape: {test_data.shape}\")\n",
    "print(f\"AD_test shape: {ad_test_data.shape}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1c888",
   "metadata": {
    "time_run": "2:55:12p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('data/train.csv'),\n",
       " Path('data/validation.csv'),\n",
       " Path('data/test.csv'),\n",
       " Path('data/AD_test.csv'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path('data')\n",
    "train_path = data_dir/'train.csv'\n",
    "val_path = data_dir/'validation.csv'\n",
    "test_path = data_dir/'test.csv'\n",
    "ad_test_path = data_dir/'AD_test.csv'\n",
    "\n",
    "train_path, val_path, test_path, ad_test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434402fe",
   "metadata": {
    "time_run": "2:55:15p"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_data, train_cols = \u001b[43mread_data_demo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[32m      2\u001b[39m ad_test_data, ad_test_cols = read_data_demo(ad_test_path)",
      "\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain data first 5 rows:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrain_data[:\u001b[32m5\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IML_2025/ex2_files/helpers.py:112\u001b[39m, in \u001b[36mread_data_demo\u001b[39m\u001b[34m(filename)\u001b[39m",
      "\u001b[32m    107\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m",
      "\u001b[32m    108\u001b[39m \u001b[33;03mRead the data from the csv file and return the features and labels as numpy arrays.\u001b[39;00m",
      "\u001b[32m    109\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m",
      "\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# the data in pandas dataframe format\u001b[39;00m",
      "\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# extract the column names\u001b[39;00m",
      "\u001b[32m    115\u001b[39m col_names = \u001b[38;5;28mlist\u001b[39m(df.columns)",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m",
      "\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(",
      "\u001b[32m   1014\u001b[39m     dialect,",
      "\u001b[32m   1015\u001b[39m     delimiter,",
      "\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,",
      "\u001b[32m   1023\u001b[39m )",
      "\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)",
      "\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m",
      "\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))",
      "\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m",
      "\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:",
      "\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m",
      "\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]",
      "\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m",
      "\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m",
      "\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:",
      "\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m",
      "\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m",
      "\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m",
      "\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m",
      "\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):",
      "\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m",
      "\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m",
      "\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:",
      "\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m",
      "\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m",
      "\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m",
      "\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:",
      "\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m",
      "\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)",
      "",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/train.csv'"
     ]
    }
   ],
   "source": [
    "train_data, train_cols = read_data_demo(train_path)\n",
    "ad_test_data, ad_test_cols = read_data_demo(ad_test_path)\n",
    "\n",
    "print(f\"Train data first 5 rows:\\n{train_data[:5]}\\n\")\n",
    "print(f\"Train columns: {train_cols}\\n\")\n",
    "print(f\"AD_test data first 5 rows:\\n{ad_test_data[:5]}\\n\")\n",
    "print(f\"AD_test columns: {ad_test_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70217172",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "\r\n",
    "check current dir and its contents\n",
    "\n",
    "##### ðŸ¤–ReplyðŸ¤–<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "```python\n",
    "Path.cwd()\n",
    "```\n",
    "\n",
    "```python\n",
    "list(Path.cwd().iterdir())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17c7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data, _ = read_data_demo(val_path)\n",
    "test_data, _ = read_data_demo(test_path)\n",
    "\n",
    "print(f\"Train shape: {train_data.shape}\")\n",
    "print(f\"Validation shape: {val_data.shape}\")\n",
    "print(f\"Test shape: {test_data.shape}\")\n",
    "print(f\"AD_test shape: {ad_test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60b4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4345fbe5-18ae-4bb9-8351-34655e265789",
   "metadata": {},
   "source": [
    "# part 1: KNN iplementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a28e4a-246a-49f5-b1cf-2f011b5e20f3",
   "metadata": {},
   "source": [
    "specification notes\n",
    "\n",
    "Algorithm 1: kNN Classification\n",
    "\n",
    "Data: Training dataset Xtrain = {(xi, yi)}N\n",
    "\n",
    "i=1, where xi âˆˆ R2 is the\n",
    "\n",
    "feature vector and yi corresponds to its class label; Test instance\n",
    "Ë†xtest; Number of neighbors k.\n",
    "\n",
    "Result: Predicted class label Ë†ytest for the test instance.\n",
    "for each training instance (xi, yi) do\n",
    "\n",
    "Calculate the distance di between xi and xtest.\n",
    "\n",
    "Sort the distances di in ascending order and select the first k instances.\n",
    "for each class c do\n",
    "\n",
    "Count the occurrences of c in the selected k instances.\n",
    "Assign the class label Ë†ytest to the one with the highest count.\n",
    "return Ë†ytest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068e10a6-afde-4f8a-a3cb-69e1b183cb46",
   "metadata": {},
   "source": [
    "\n",
    "class KNNClassifier:\n",
    "    def __init__(self, k, distance_metric='l2'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train = None\n",
    "        self.Y_train = None\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        Update the kNN classifier with the provided training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train (numpy array) of size (N, d): Training feature vectors.\n",
    "        - Y_train (numpy array) of size (N,): Corresponding class labels.\n",
    "        \"\"\"\n",
    "        self.X_train = X_train.astype(np.float32)\n",
    "        self.Y_train = Y_train\n",
    "        d = self.X_train.shape[1]\n",
    "        if self.distance_metric == 'l2':\n",
    "            self.index = faiss.index_factory(d, \"Flat\", faiss.METRIC_L2)\n",
    "        elif self.distance_metric == 'l1':\n",
    "            self.index = faiss.index_factory(d, \"Flat\", faiss.METRIC_L1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        pass\n",
    "        self.index.add(self.X_train)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels for the given data.\n",
    "\n",
    "        Parameters:\n",
    "        - X (numpy array) of size (M, d): Feature vectors.\n",
    "\n",
    "        Returns:\n",
    "        - (numpy array) of size (M,): Predicted class labels.\n",
    "        \"\"\"\n",
    "        #### YOUR CODE GOES HERE ####\n",
    "\n",
    "    def knn_distance(self, X):\n",
    "        \"\"\"\n",
    "        Calculate kNN distances for the given data. You must use the faiss library to compute the distances.\n",
    "        See lecture slides and https://github.com/facebookresearch/faiss/wiki/Getting-started#in-python-2 for more information.\n",
    "\n",
    "        Parameters:\n",
    "        - X (numpy array) of size (M, d): Feature vectors.\n",
    "\n",
    "        Returns:\n",
    "        - (numpy array) of size (M, k): kNN distances.\n",
    "        - (numpy array) of size (M, k): Indices of kNNs.\n",
    "        \"\"\"\n",
    "        X = X.astype(np.float32)\n",
    "\t#### YOUR CODE GOES HERE ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640363c4-673a-4d8c-880a-cd6091555360",
   "metadata": {},
   "source": [
    "things i need to understand:\n",
    "\n",
    "how does faiss knn work? what happens in fit?\n",
    "we need to be able to play with the internals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb71653-2042-4714-b09f-1bfce197e131",
   "metadata": {},
   "source": [
    "notes: since our data lives in 2 d, can we use heuristics to pull top k closest neightbours without going over all data?\n",
    "\n",
    "create some kind of lookup bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f68580-1aac-4473-8f54-4bde719f91a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8fd7644-728a-4c5f-8f4a-8db3337a5368",
   "metadata": {},
   "source": [
    "## KNN grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9865b59-ce50-4d69-b9e1-8809f42600dc",
   "metadata": {},
   "source": [
    "**Grid search:** Train kNN for all combinations of k âˆˆ {1, 10, 100, 1000, 3000} Ã— distance âˆˆ {L1, L2}. Create 5Ã—2 table of test accuracies. Save all 10 models with their hyperparameters and test accuracies.\n",
    "\n",
    "**Questions:**\n",
    "1. What's the trend as k increases? Does it differ by distance metric?\n",
    "2. Visualize decision boundaries for: (i) L2 with k_max (best accuracy), (ii) L2 with k_min (worst accuracy), (iii) L1 with k_max\n",
    "   - (a) Compare k_max vs k_min with L2: why does k_max perform better?\n",
    "   - (b) Compare L2 vs L1 with k_max: how does distance metric affect the space?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37798c3-0eb1-47ae-ab2a-e313b5d841ae",
   "metadata": {},
   "source": [
    "think about the problem - what would you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db7ed1b-53ae-4a0c-9659-b388a32f4bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d311c95-3f85-4863-9ffe-2e25696a7e65",
   "metadata": {},
   "source": [
    "### KNN decision boundaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a3645b-59fd-4e09-aa12-9c3fc5b9f998",
   "metadata": {},
   "source": [
    "**Task:** Use `plot_decision_boundaries()` helper to visualize 3 models on test data:\n",
    "1. L2 distance, k = k_max (highest test accuracy)\n",
    "2. L2 distance, k = k_min (lowest test accuracy)  \n",
    "3. L1 distance, k = k_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe852eb2-7baa-4860-a888-b80c8a7a0d8a",
   "metadata": {},
   "source": [
    "## Anomaly detection\n",
    "\n",
    "**Task:** Use AD_test.csv as test set, train.csv as single class (ignore labels).\n",
    "1. Find 5 nearest neighbors (L2 distance) for each AD_test sample\n",
    "2. Sum the 5 distances = anomaly score per sample\n",
    "3. Select top 50 samples with highest scores = anomalies, rest = normal\n",
    "4. Plot: AD_test colored by prediction (blue=normal, red=anomaly) + train.csv in black with alpha=0.01\n",
    "\n",
    "**Question:** What characterizes the anomalies? How do they differ from normal data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff9845-2dee-4fea-b3f2-68cc354c2155",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "934e3feb-fe02-4377-bffc-07f595685cf0",
   "metadata": {},
   "source": [
    "# trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d86026c-ae06-4ef7-88f8-b9d48513b271",
   "metadata": {},
   "source": [
    "## Understanding trees - interactive exploration\n",
    "\n",
    "**Goal:** Interact with tree components to understand how predictions work.\n",
    "- Create a simple tree, examine its structure (tree_.feature, tree_.threshold, tree_.children_left/right, tree_.value)\n",
    "- Manually trace a prediction path for a sample point\n",
    "- Understand how tree.predict() navigates the tree structure\n",
    "\n",
    "**Visualization library:** `sklearn.tree.plot_tree()` or `graphviz` for tree visualization. For more advanced viz, use `dtreeviz` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aijcnadqci",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree visualization series placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4yzzs4x68vr",
   "metadata": {},
   "source": [
    "## Visualizing tree complexity\n",
    "\n",
    "**Series 1 - Fixed depth=1, varying leaves:**\n",
    "Train and visualize trees with max_depth=1 and max_leaf_nodes âˆˆ {2, 4, 8, 24, 50, 100}\n",
    "\n",
    "**Series 2 - Varying depth, controlled leaves:**\n",
    "Train and visualize trees with max_depth âˆˆ {2, 4, 8, 16, 32, 50} and appropriate max_leaf_nodes to observe depth effects\n",
    "\n",
    "**Goal:** Understand how depth vs leaf constraints affect tree structure and decision boundaries.\n",
    "\n",
    "**Visualization:** Use `sklearn.tree.plot_tree()` for tree structure or `plot_decision_boundaries()` for geographic space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85450dee-9e03-42b9-a915-aca5a5f1e154",
   "metadata": {},
   "source": [
    "## train 24 trees\n",
    "\n",
    "**Task:** Train DecisionTreeClassifier for all combinations of max_depth âˆˆ {1, 2, 4, 6, 10, 20, 50, 100} Ã— max_leaf_nodes âˆˆ {50, 100, 1000}. Save all 24 models with their hyperparameters (max_depth, max_leaf_nodes) and accuracies (train, validation, test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdae74f7-7122-4530-9c2a-8f4eb94fc738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fc7b504-2620-49f3-9c4c-6ba111c8e029",
   "metadata": {},
   "source": [
    "## tree analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100e318-b5dd-408d-bfb2-98674fdae772",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "1. Report test accuracy of tree with best validation accuracy\n",
    "2. Does this tree generalize well? Is validation set sufficient for selection?\n",
    "3. Are 50 leaf nodes enough for perfect accuracy with 50 states? Why/why not?\n",
    "4. Visualize decision boundaries for best tree from Q1. What shapes do classes form?\n",
    "5. Find best tree with exactly 50 leaf nodes. Visualize and compare to Q1 best tree.\n",
    "6. Find best tree with max_depth â‰¤ 6. Visualize and compare space division to Q4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f6604b-51a4-4073-98fe-a7fb917c55f2",
   "metadata": {},
   "source": [
    "think and research - how many leaves do trees? how many boundaries can a tree make? how many hyper planes?\n",
    "\n",
    "ask chat gpt for deep think"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9746815-6cf6-4507-adc6-c9a7509780d7",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f03b78f-6f2c-43b2-afac-29a153b44088",
   "metadata": {},
   "source": [
    "**Task:** Train RandomForestClassifier with n_estimators=300, max_depth=6. Visualize decision boundaries. \n",
    "\n",
    "**Question:** Is this model more expressive than single tree from Q1? How does visualization show this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea7c1f-4639-4ffe-873b-87842cc4e0cd",
   "metadata": {},
   "source": [
    "# bonus: boosted trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecaa860-800d-4189-8b59-b68a43f0dab9",
   "metadata": {},
   "source": [
    "**Bonus (5 pts):** Train XGBClassifier with n_estimators=300, max_depth=6, learning_rate=0.1. Report test accuracy and visualize predictions. Compare to random forest: how do predictions differ? Which performs better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da80513-2a81-462f-afab-e47b305be6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff5c4634-9135-4d25-ac39-28c81d23eac3",
   "metadata": {},
   "source": [
    "## interpret Ml explainable boosting classifier\n",
    "\n",
    "instead of xgb trees, use the glassbox EBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a988d2-cc9f-4ad3-931e-932d53df3b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "concise",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
