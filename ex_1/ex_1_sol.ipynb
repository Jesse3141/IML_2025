{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9374c2f7",
   "metadata": {},
   "source": [
    "# background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5674f26",
   "metadata": {},
   "source": [
    "\r\n",
    "we are given:\r\n",
    "\r\n",
    "Data: data.pkl â†’ train_y (10,000), test_y (1,000). Boolean/0-1 outcomes.\r\n",
    "and for each scenario we have the 'prophet' predictions:\r\n",
    "```\r\n",
    "scenario_five_prophets.pkl\r\n",
    "scenario_one_and_two_prophets.pkl\r\n",
    "scenario_six_prophets.pkl\r\n",
    "scenario_three_and_four_prophets.pkl\r\n",
    "```\r\n",
    "\r\n",
    "we will use the game data and the 'prophets' (ie models) prediction to calculate stats on the predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f82a33c",
   "metadata": {},
   "source": [
    "important terms describing a model (a prophet):\r\n",
    "\r\n",
    "True risk: ground truth of prophet probabilaty of being correct on **true** population - not the train or test set. \r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4080d2",
   "metadata": {},
   "source": [
    "\r\n",
    "The ERM algorithm simply chooses the prophet with the fewest training errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c255d34c",
   "metadata": {},
   "source": [
    "## coding conventions:\r\n",
    "\r\n",
    "when sampling games or prophets, sample uniformly with seed 3141\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439eae71",
   "metadata": {},
   "source": [
    "\r\n",
    "## examine data and prophets\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c39d59",
   "metadata": {
    "time_run": "12:40:52p"
   },
   "outputs": [],
   "source": [
    "import pickle\r\n",
    "\r\n",
    "# Load the game data\r\n",
    "with open('data.pkl', 'rb') as f:\r\n",
    "    data = pickle.load(f)\r\n",
    "\r\n",
    "\r\n",
    "with open('scenario_one_and_two_prophets.pkl', 'rb') as f:\r\n",
    "    scenario_one_two = pickle.load(f)\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af04ed2",
   "metadata": {
    "skipped": true,
    "time_run": "12:31:11p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train_set', 'test_set'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9c29f",
   "metadata": {
    "skipped": true,
    "time_run": "12:32:11p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set with shape data[key].shape=(10000,)\n",
      "test_set with shape data[key].shape=(1000,)\n"
     ]
    }
   ],
   "source": [
    "for key in data.keys():\r\n",
    "    print(f'{key} with shape {data[key].shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdf1ac2",
   "metadata": {
    "skipped": true,
    "time_run": "12:34:09p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set with shape scenario_one_two[key].shape=(2, 10000)\n",
      "test_set with shape scenario_one_two[key].shape=(2, 1000)\n",
      "true_risk with shape scenario_one_two[key].shape=(2,)\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "for key in scenario_one_two.keys():\r\n",
    "    print(f'{key} with shape {scenario_one_two[key].shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7cfa6a",
   "metadata": {
    "skipped": true,
    "time_run": "12:36:31p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\r\n",
    "scenario_one_two['true_risk']\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2393d8",
   "metadata": {},
   "source": [
    "lets' summarise the data:\r\n",
    "data: a dict with keys and bool matrices of game reuslts:  \r\n",
    "\r\n",
    "game data: a dict names data with keys: `dict_keys(['train_set', 'test_set'])`\r\n",
    "```\r\n",
    "train_set with shape data[key].shape=(10000,)\r\n",
    "test_set with shape data[key].shape=(1000,)\r\n",
    "```\r\n",
    "\r\n",
    "prohpet data:\r\n",
    "a dict scenario_one_two with keys: `dict_keys(['train_set', 'test_set', 'true_risk'])`\r\n",
    "```\r\n",
    "train_set with shape scenario_one_two[key].shape=(2, 10000) # bool\r\n",
    "test_set with shape scenario_one_two[key].shape=(2, 1000)\r\n",
    "true_risk with shape scenario_one_two[key].shape=(2,) # float\r\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5abd06",
   "metadata": {},
   "source": [
    "so in scenario 1 and 2 there are 2 prohpets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5317989f",
   "metadata": {},
   "source": [
    "# general code:\r\n",
    "\r\n",
    "things that run before all scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d3a126",
   "metadata": {
    "time_run": "1:08:47p"
   },
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pickle\r\n",
    "\r\n",
    "np.random.seed(3141)\r\n",
    "\r\n",
    "# Load the game data\r\n",
    "with open('data.pkl', 'rb') as f:\r\n",
    "    data = pickle.load(f)\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f14219",
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f273b75",
   "metadata": {
    "time_run": "12:51:40p"
   },
   "outputs": [],
   "source": [
    "def erm_prophet(games, predictions):\r\n",
    "    \"\"\"Returns index of prophet with lowest error on games.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        games: array of shape (n,) with true outcomes (boolean/0-1)\r\n",
    "        predictions: array of shape (k, n) with k prophets' predictions\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "        int: index of prophet with minimum error\r\n",
    "    \"\"\"\r\n",
    "    errors = (predictions != games).sum(axis=1)\r\n",
    "    return errors.argmin()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10056d",
   "metadata": {
    "time_run": "1:34:37p"
   },
   "outputs": [],
   "source": [
    "def evaluate_prophet(prophet_data, selected_prophet_idx, game_data):\r\n",
    "    \"\"\"Evaluate approximation and estimation error.\r\n",
    "    \r\n",
    "    Args:\r\n",
    "        prophet_data: dict with 'true_risk' array and 'test_set' predictions\r\n",
    "        selected_prophet_idx: index of prophet selected by ERM\r\n",
    "        game_data: dict with 'test_set' true outcomes\r\n",
    "    \r\n",
    "    Returns:\r\n",
    "        dict: {'test_set_error', 'approximation_error', 'estimation_error'}\r\n",
    "    \"\"\"\r\n",
    "    true_risks = prophet_data['true_risk']\r\n",
    "    best_true_risk = true_risks.min()\r\n",
    "    selected_true_risk = true_risks[selected_prophet_idx]\r\n",
    "    \r\n",
    "    approximation_error = best_true_risk\r\n",
    "    estimation_error = selected_true_risk - best_true_risk\r\n",
    "    \r\n",
    "    # Evaluate on test set\r\n",
    "    test_predictions = prophet_data['test_set'][selected_prophet_idx]\r\n",
    "    test_outcomes = game_data['test_set']\r\n",
    "    test_set_error = (test_predictions != test_outcomes).mean()\r\n",
    "    \r\n",
    "    return {\r\n",
    "        'test_set_error': test_set_error,\r\n",
    "        'approximation_error': approximation_error,\r\n",
    "        'estimation_error': estimation_error\r\n",
    "    }\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51360e",
   "metadata": {
    "time_run": "1:49:17p"
   },
   "outputs": [],
   "source": [
    "def bootstrap_erm(game_data:dict, prophet_data:dict, n_trials:int, seed:int=3141, verbose: bool = False) -> dict:\n",
    "    \"\"\"Run bootstrap trials selecting prophet via ERM on single training games, return aggregated statistics\n",
    "    \n",
    "    it aggreagates results from &evaluate_prophet and calculates stats\n",
    "    the mean of test set error over all trials\n",
    "    the number of times in which the we chose the 'best' model (estiamtion error 0)\n",
    "    the mean of the approximation errors\n",
    "    the mean of the estiamtion errors\n",
    "\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_trials):\n",
    "        game_idx = np.random.randint(0, len(game_data['train_set']))\n",
    "        game_result = game_data['train_set'][game_idx:game_idx+1]\n",
    "        prophet_preds = prophet_data['train_set'][:, game_idx:game_idx+1]\n",
    "        \n",
    "        selected = erm_prophet(game_result, prophet_preds)\n",
    "        eval_result = evaluate_prophet(prophet_data, selected, game_data)\n",
    "        results.append(eval_result)\n",
    "    \n",
    "        if verbose:\n",
    "                print(f\"Trial {i+1}: game={game_result[0]}, prophet={selected}, preds={prophet_preds[selected]}, test_err={eval_result['test_set_error']:.3f}, approx_err={eval_result['approximation_error']:.3f}, est_err={eval_result['estimation_error']:.3f}\")\n",
    "    \n",
    "    test_errors = [r['test_set_error'] for r in results]\n",
    "    estimation_errors = [r['estimation_error'] for r in results]\n",
    "    approximation_errors = [r['approximation_error'] for r in results]\n",
    "    \n",
    "    return {\n",
    "        'mean_test_error': np.mean(test_errors),\n",
    "        'best_model_count': sum(e == 0 for e in estimation_errors),\n",
    "        'mean_approximation_error': np.mean(approximation_errors),\n",
    "        'mean_estimation_error': np.mean(estimation_errors)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d99e2",
   "metadata": {},
   "source": [
    "# part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04927dd",
   "metadata": {},
   "source": [
    "Scenario 1: Two prophets, One game.\r\n",
    "Load the file scenario one and two prophets.pkl\r\n",
    "You have two prophets, one prophet with an 20% error and another prophet\r\n",
    "with 40% error. You decide to evaluate each prophet on a single random game\r\n",
    "(i.e. train set of size of 1), using the ERM algorithm to choose the best one.\r\n",
    "Repeat this experiment 100 times each time selecting the best prophet using\r\n",
    "the ERM algorithm. For each experiment:\r\n",
    "1. Select a prophet based on the ERM algorithm Evaluate your selected\r\n",
    "prophet on the test set and compute its average error.\r\n",
    "Calculate the\r\n",
    "approximation2 and estimation error3\r\n",
    "In your report\r\n",
    "â€¢ Report the average error of the selected prophets over the experiments.\r\n",
    "â€¢ In how many experiments did you choose the best4 prophet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5a47c",
   "metadata": {
    "skipped": true,
    "time_run": "12:54:33p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game index: 3432\n",
      "Game result: False\n",
      "Prophet predictions: [False False]\n",
      "ERM chose prophet: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "np.random.seed(3141)\r\n",
    "game_idx = np.random.randint(0, 10000)\r\n",
    "\r\n",
    "game_result = data['train_set'][game_idx]\r\n",
    "prophet_predictions = scenario_one_two['train_set'][:, game_idx]\r\n",
    "\r\n",
    "print(f\"Game index: {game_idx}\")\r\n",
    "print(f\"Game result: {game_result}\")\r\n",
    "print(f\"Prophet predictions: {prophet_predictions}\")\r\n",
    "\r\n",
    "chosen = erm_prophet(game_result, prophet_predictions.reshape(-1, 1))\r\n",
    "print(f\"ERM chose prophet: {chosen}\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1282d89",
   "metadata": {
    "skipped": true,
    "time_run": "1:23:21p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2), np.float64(0.0))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\r\n",
    "evaluate_prophet(prophet_data=scenario_one_two,selected_prophet_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05db178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a9da8",
   "metadata": {
    "time_run": "1:50:06p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_test_error': np.float64(0.21396),\n",
       " 'best_model_count': np.int64(91),\n",
       " 'mean_approximation_error': np.float64(0.19999999999999996),\n",
       " 'mean_estimation_error': np.float64(0.018000000000000002)}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bootstrap_erm(data,scenario_one_two,100,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891c051b",
   "metadata": {
    "skipped": true,
    "time_run": "1:51:02p"
   },
   "outputs": [],
   "source": [
    "\r\n",
    "def Scenario_1():\r\n",
    "    \"\"\"\r\n",
    "    Question 1.\r\n",
    "    2 Prophets 1 Game.\r\n",
    "    You may change the input & output parameters of the function as you wish.\r\n",
    "    \"\"\"\r\n",
    "    np.random.seed(3141)\r\n",
    "    with open('scenario_one_and_two_prophets.pkl', 'rb') as f:\r\n",
    "        scenario_one_two = pickle.load(f)\r\n",
    "    res = bootstrap_erm(data,scenario_one_two,100,verbose=False)\r\n",
    "\r\n",
    "    return res\r\n",
    "\r\n",
    "    \r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scenario_2():\n",
    "    \"\"\"\n",
    "    Question 2.\n",
    "    2 Prophets 10 Games.\n",
    "    You may change the input & output parameters of the function as you wish.\n",
    "    \"\"\"\n",
    "    ############### YOUR CODE GOES HERE ###############\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e1a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scenario_3():\n",
    "    \"\"\"\n",
    "    Question 3.\n",
    "    500 Prophets 10 Games.\n",
    "    You may change the input & output parameters of the function as you wish.\n",
    "    \"\"\"\n",
    "    ############### YOUR CODE GOES HERE ###############\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scenario_4():\n",
    "    \"\"\"\n",
    "    Question 4.\n",
    "    500 Prophets 1000 Games.\n",
    "    You may change the input & output parameters of the function as you wish.\n",
    "    \"\"\"\n",
    "    ############### YOUR CODE GOES HERE ###############\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d854ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scenario_5():\n",
    "    \"\"\"\n",
    "    Question 5.\n",
    "    School of Prophets.\n",
    "    You may change the input & output parameters of the function as you wish.\n",
    "    \"\"\"\n",
    "    ############### YOUR CODE GOES HERE ###############\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0180d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scenario_6():\n",
    "    \"\"\"\n",
    "    Question 6.\n",
    "    The Bias-Variance Tradeoff.\n",
    "    You may change the input & output parameters of the function as you wish.\n",
    "    \"\"\"\n",
    "    ############### YOUR CODE GOES HERE ###############\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768c9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "\n",
    "    print(f'Scenario 1 Results:')\n",
    "    Scenario_1()\n",
    "\n",
    "    print(f'Scenario 2 Results:')\n",
    "    Scenario_2()\n",
    "\n",
    "    print(f'Scenario 3 Results:')\n",
    "    Scenario_3()\n",
    "\n",
    "    print(f'Scenario 4 Results:')\n",
    "    Scenario_4()\n",
    "\n",
    "    print(f'Scenario 5 Results:')\n",
    "    Scenario_5()\n",
    "\n",
    "    print(f'Scenario 6 Results:')\n",
    "    Scenario_6()"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "concise",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
